{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b74b14",
   "metadata": {},
   "source": [
    "# Scaling-Up Raster Data Analysis\n",
    "\n",
    "*March 12, 2024*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf55c06",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install dask numpy scipy\n",
    "```\n",
    "\n",
    "[**Download the dataset here and it make it accessible to this notebook.**](http://files.ntsg.umt.edu/data/GIS_Programming/data/MOD17A3HGF_C61_h19v08_annual_NPP_gCm-2yr-1_2001-2021.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "hdf = h5py.File('data/MOD17A3HGF_C61_h19v08_annual_NPP_gCm-2yr-1_2001-2021.h5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2808e8d-68de-43bf-95b0-d79682c13e33",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- A good chip circa 2004: [https://en.wikipedia.org/wiki/Pentium_4](https://en.wikipedia.org/wiki/Pentium_4)\n",
    "- A good chip circa 2024: [https://ark.intel.com/content/www/us/en/ark/products/236781/intel-core-i7-processor-14700-33m-cache-up-to-5-40-ghz.html](https://ark.intel.com/content/www/us/en/ark/products/236781/intel-core-i7-processor-14700-33m-cache-up-to-5-40-ghz.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ade19a",
   "metadata": {},
   "source": [
    "## Bottlenecks in Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3887c1",
   "metadata": {},
   "source": [
    "![](Moore.png)\n",
    "\n",
    "*Image courtesy of XSEDE*\n",
    "\n",
    "[Quantum tunneling is one of the reasons it's hard to make smaller and smaller transistors.](https://en.wikipedia.org/wiki/Quantum_tunnelling#Electronics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f11c33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Before we start working with huge raster datasets, let's explore some of the basic tools involved in parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    result = 1\n",
    "    for i in range(n, 1, -1):\n",
    "        result = result * i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4747e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import timeit\n",
    "\n",
    "times = []\n",
    "for n in my_numbers:\n",
    "    t = timeit.timeit(f\"factorial({n})\", globals = globals(), number = 1000)\n",
    "    times.append(t)\n",
    "    \n",
    "pyplot.bar(my_numbers, times)\n",
    "pyplot.xlabel('Number of Values')\n",
    "pyplot.ylabel('Execution Time (secs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d61f2-fd24-4389-b3b2-a1ccced037bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concurrent Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70645f6-ed5b-4cbb-99b0-3d43e9f2aec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bottlenecks in Array Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112434a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analyzing Large Raster Data Cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "hdf = h5py.File('data/MOD17A3HGF_C61_h19v08_annual_NPP_gCm-2yr-1_2001-2021.h5', 'r')\n",
    "npp = hdf['NPP'][:]\n",
    "hdf.close()\n",
    "\n",
    "npp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def linear_trend(array, n_years = 21):\n",
    "    # linregress(x, y) takes two arguments: y is regressed on x\n",
    "    result = stats.linregress(np.arange(0, n_years), array)\n",
    "    return result[0] # Just the slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062908cf",
   "metadata": {},
   "source": [
    "### Estimating Time to Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f52f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8546354",
   "metadata": {},
   "source": [
    "## Concurrency in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c172e5c",
   "metadata": {},
   "source": [
    "![](concurrency.jpg)\n",
    "\n",
    "*Image by Kelvin Wahome*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feeac03",
   "metadata": {},
   "source": [
    "### Independent Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6c582",
   "metadata": {},
   "source": [
    "### How Many Processes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f669ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil \n",
    "\n",
    "psutil.cpu_count(logical = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77f518",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885e663",
   "metadata": {},
   "source": [
    "## Concurrent Raster Data Processing\n",
    "\n",
    "**Now, let's see how to actually do concurrent raster processing with `dask`.**\n",
    "\n",
    "When doing concurrent operations on arrays, we want to let `dask` do most of the work figuring out exactly how to chunk up the spatial domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6cd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxval(x):\n",
    "    return np.array([np.max(x[:,i]) for i in range(0, x[0].size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41e8c4-2c38-47ff-9b20-4c51db2cfe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea1bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_npp = da.from_array(npp).reshape((21, 2400*2400)).rechunk((-1, 'auto'), block_size_limit = 65e6)\n",
    "d_npp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be4272-ea33-43ed-b37b-41d8a482a7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129cbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_npp = da.from_array(npp).reshape((21, 2400*2400)).rechunk((-1, 1440000))\n",
    "d_npp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c7ef6-c3db-4642-a1ed-432f77eafe6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "max_npp = max_npp.reshape((2400,2400)).astype(np.float32)\n",
    "max_npp[max_npp < 0] = np.nan\n",
    "\n",
    "pyplot.imshow(max_npp, interpolation = 'nearest')\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fcd9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## At Home: Calculate a Linear Trend\n",
    "\n",
    "Try running `map_blocks()` with a different function! The `linear_trend2()` function, below, is designed to calculate linear trends on each pixel in a block of pixels, so it can be used with `dask` and `map_blocks()` to calculate trends over large raster data cubes.\n",
    "\n",
    "This took about 10 minutes with 4 processes on my Intel i7 CPU at home. You should expect it to take about the same amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_trend2(block, n_years = 21):\n",
    "    x_data = np.arange(0, n_years)\n",
    "    # A fancy way of saying call stats.linregress() in a for loop,\n",
    "    #    once for each pixel in the block\n",
    "    return np.array([\n",
    "        stats.linregress(x_data, block[:,i])[0]\n",
    "        for i in range(0, block[0].size)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62f3da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min 4s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "result = d_npp.map_blocks(linear_trend2, drop_axis = 0, dtype = np.int16)\n",
    "result.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
